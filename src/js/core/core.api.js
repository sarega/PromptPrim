// ===============================================
// FILE: src/js/core/core.api.js 
// DESCRIPTION: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Model ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô Gemma 3 27B
// ===============================================

import { stateManager } from './core.state.js';
import * as UserService from '../modules/user/user.service.js'; // <-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ import ‡∏ô‡∏µ‡πâ
import { estimateTokens } from '../modules/chat/chat.handlers.js';

// import { recommendedModelIds } from './core.state.js';

const modelCapabilities = {
    // Perplexity ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ params ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å tools parameter
    'perplexity/sonar-small-online': { penalties: false, seed: false, top_k: false, tools: false },
    'perplexity/sonar-medium-online': { penalties: false, seed: false, top_k: false, tools: false },
    // Grok (xAI) ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Penalties ‡πÅ‡∏•‡∏∞ Seed
    'xai/grok-1.5': { penalties: false, seed: false },
};

/**
 * ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
 * @param {string} modelId - ID ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
 * @param {string} capability - ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (e.g., 'penalties', 'seed', 'tools')
 * @returns {boolean} - ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ true ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö, false ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
 */
function getCapability(modelData, capability) {
    if (!modelData || !modelData.id) return false; // ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô

    const modelId = modelData.id;
    const specificCaps = modelCapabilities[modelId];
    if (specificCaps && specificCaps[capability] !== undefined) {
        return specificCaps[capability];
    }

    switch (capability) {
        case 'penalties':
        case 'seed':
            return !modelId.startsWith('xai/') && !modelId.startsWith('perplexity/');
        case 'tools':
            // [FIX] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Logic ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ modelData ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
            return !modelId.startsWith('perplexity/') && modelData.supports_tools;
        default:
            return true;
    }
}

// --- Helper sub-functions (not exported, private to this module) ---
async function fetchOpenRouterModels(apiKey) {
    const response = await fetch('https://openrouter.ai/api/v1/models', { 
        headers: { 'Authorization': `Bearer ${apiKey}` } 
    });
    if (!response.ok) throw new Error('Could not fetch models from OpenRouter');
    const data = await response.json();
    return data.data.map(m => ({ 
        id: m.id, 
        name: m.name || m.id, 
        provider: 'openrouter',
        description: m.description,
        context_length: m.context_length,
        pricing: {
            prompt: m.pricing?.prompt || '0',
            completion: m.pricing?.completion || '0'
        },
        supports_tools: m.architecture?.tool_use === true 
    }));
}

async function fetchOllamaModels(baseUrl) {
    try {
        const response = await fetch(`${baseUrl}/api/tags`);
        if (!response.ok) throw new Error(`Ollama connection failed (HTTP ${response.status})`);
        const data = await response.json();
        return data.models.map(m => ({ id: m.name, name: m.name, provider: 'ollama', supports_tools: false }));
    } catch (error) {
        throw new Error('Could not connect to Ollama. Check URL and CORS settings.');
    }
}

async function fetchWithTimeout(resource, options = {}, timeout = 120000) {
    const controller = new AbortController();
    const id = setTimeout(() => controller.abort(), timeout);
    const signal = AbortSignal.any([options.signal, controller.signal].filter(Boolean));
    try {
        return await fetch(resource, { ...options, signal });
    } finally {
        clearTimeout(id);
    }
}

// --- Main Exported Functions ---
// [REVISED & COMPLETE] src/js/core/core.api.js

export async function loadAllProviderModels() {
    stateManager.bus.publish('status:update', { message: 'Loading models...', state: 'loading' });

    const apiKey = UserService.getApiKey();
    const baseUrl = UserService.getOllamaUrl();
    
    let allModels = [];
    try {
        const fetchPromises = [];
        if (apiKey) {
            fetchPromises.push(fetchOpenRouterModels(apiKey).catch(e => { console.error("OpenRouter fetch failed:", e); return []; }));
        }
        if (baseUrl) {
            fetchPromises.push(fetchOllamaModels(baseUrl).catch(e => { console.error("Ollama fetch failed:", e); return []; }));
        }
        const results = await Promise.all(fetchPromises);
        allModels = results.flat();
    } catch (error) {
        stateManager.bus.publish('status:update', { message: `Error loading models: ${error.message}`, state: 'error' });
        return;
    }
    
    // [FIX START] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Logic ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï State
    
    // 1. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Model ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡∏•‡∏á State ‡∏Å‡πà‡∏≠‡∏ô
    stateManager.setAllModels(allModels);

    // 2. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ó‡∏µ‡πà‡∏°‡∏µ Model ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    const project = stateManager.getProject();
    let projectWasChanged = false;

    if (allModels.length > 0 && project) {
        const systemAgent = project.globalSettings.systemUtilityAgent;
        const defaultAgent = project.agentPresets['Default Agent'];
        
        if (systemAgent && (!systemAgent.model || !allModels.some(m => m.id === systemAgent.model))) {
            const preferredDefaults = ['google/gemma-3-27b-it', 'openai/gpt-4o-mini'];
            const availableDefaultModel = preferredDefaults.find(pdm => allModels.some(am => am.id === pdm));
            if (availableDefaultModel) {
                systemAgent.model = availableDefaultModel;
                if (defaultAgent) defaultAgent.model = availableDefaultModel;
                projectWasChanged = true;
            }
        }
    }
    
    // 3. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
    if (projectWasChanged) {
        stateManager.setProject(project);
    }
    
    // 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° Status ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô State ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß
    const finalModelList = stateManager.getState().allProviderModels || [];
    const statusMessage = finalModelList.length > 0 ? `Loaded ${finalModelList.length} models.` : 'No models found.';
    stateManager.bus.publish('status:update', { message: statusMessage, state: 'connected' });
    // [FIX END]
}
export function getFullSystemPrompt(agentName) {
    const project = stateManager.getProject();
    if (!project) return "";
    let entityAgent;
    const activeEntity = project.activeEntity;
    const targetName = agentName || activeEntity?.name;
    const targetType = agentName ? 'agent' : activeEntity?.type;
    if (!targetName) return "";
    if (targetType === 'agent') {
        entityAgent = project.agentPresets?.[targetName];
    } else if (targetType === 'group') {
        const group = project.agentGroups?.[targetName];
        entityAgent = project.agentPresets?.[group?.moderatorAgent];
    }
    if (!entityAgent) return "";
    let basePrompt = entityAgent.systemPrompt || "";
    const activeMemoryNames = entityAgent.activeMemories || [];
    if (activeMemoryNames.length === 0) {
        return basePrompt.trim();
    }
    const memoryContent = activeMemoryNames
        .map(name => {
            const memory = project.memories.find(m => m.name === name);
            return memory ? memory.content : '';
        })
        .filter(content => content)
        .join('\n\n');
    if (!memoryContent) {
        return basePrompt.trim();
    }
    const finalPrompt = `${basePrompt.trim()}\n\n--- Active Memories ---\n${memoryContent}`;
    return finalPrompt;
}

export function buildPayloadMessages(history, targetAgentName) {
    const project = stateManager.getProject();
    const agent = project.agentPresets[targetAgentName];
    if (!agent) return [];
    
    // [FIX] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• modelData ‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ
    const allModels = stateManager.getState().allProviderModels;
    const modelData = allModels.find(m => m.id === agent.model);
    
    const messages = [];
    const finalSystemPrompt = getFullSystemPrompt(targetAgentName);
    if (finalSystemPrompt) {
        messages.push({ role: 'system', content: finalSystemPrompt });
    }

    history.forEach(msg => {
        if (msg.isLoading || !msg.content) return;

        let apiMessageContent = msg.content;

        // --- Logic ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á Content ---
        // ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Array (‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô multimodal)
        if (Array.isArray(apiMessageContent)) {
            // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Model ‡∏ô‡∏µ‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Array content ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            // (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ OpenRouter ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ‡πÅ‡∏•‡∏∞ Ollama ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
            const supportsMultimodalArray = modelData?.provider === 'openrouter';

            if (supportsMultimodalArray) {
                // ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenRouter: ‡πÅ‡∏õ‡∏•‡∏á image_url format ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                apiMessageContent = apiMessageContent.map(part => {
                    if (part.type === 'image_url') {
                        return { type: 'image_url', image_url: { url: part.url } };
                    }
                    return part;
                });
            } else {
                // ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ollama: ‡πÅ‡∏õ‡∏•‡∏á Array ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô String ‡∏•‡πâ‡∏ß‡∏ô‡πÜ
                apiMessageContent = apiMessageContent
                    .filter(part => part.type === 'text' && part.text)
                    .map(part => part.text)
                    .join('\n');
            }
        }
        
        const apiMessage = {
            role: msg.role,
            content: apiMessageContent
        };
        
        messages.push(apiMessage);
    });

    return messages;
}

export async function generateAndRenameSession(history){
     try{
        const project = stateManager.getProject();
        if(project.activeEntity.type !== 'agent') return;

        const agentName = project.activeEntity.name;
        const agent = project.agentPresets[agentName];
        if(!agent || !agent.model) return;
        
        const titlePrompt = `Based on the conversation, generate a concise title (3-5 words) and a single relevant emoji. Respond with a JSON object like {"title": "your title", "emoji": "üëç"}.`;
        
        const messages = [{ role: "user", content: titlePrompt }];
        const responseText = await callLLM({ ...agent, temperature: 0.2 }, messages);
        
        let newTitleData = {};
        try { newTitleData = JSON.parse(responseText.match(/{.*}/s)[0]); } 
        catch(e) { 
            console.error("Failed to parse title JSON:", responseText); 
            const titlePart = responseText.replace(/"/g, '').substring(0, 30);
            newTitleData = { title: titlePart, emoji: 'üí¨' };
        }
        
        const newTitle = `${newTitleData.emoji || 'üí¨'} ${newTitleData.title || 'Untitled'}`;

        if (newTitle) {
            stateManager.bus.publish('session:autoRename', { 
                sessionId: project.activeSessionId, 
                newName: newTitle 
            });
        }
    } catch(e) {
        console.error("Auto-rename failed:", e);
    }
}

function constructApiCall(agent, messages, stream = false) {
    const project = stateManager.getProject();
    console.log("API call sees these globalSettings:", project.globalSettings);

    const allModels = stateManager.getState().allProviderModels;
    const modelData = allModels.find(m => m.id === agent.model);
    if (!modelData) throw new Error(`Model data for agent.model ID '${agent.model}' not found.`);

    const provider = modelData.provider;
    let url, headers, body;

    const commonParams = {
        temperature: parseFloat(agent.temperature),
        top_p: parseFloat(agent.topP),
        top_k: parseInt(agent.topK, 10),
        presence_penalty: parseFloat(agent.presence_penalty),
        frequency_penalty: parseFloat(agent.frequency_penalty),
        max_tokens: parseInt(agent.max_tokens, 10),
        seed: parseInt(agent.seed, 10),
        stop: agent.stop_sequences ? agent.stop_sequences.split(',').map(s => s.trim()).filter(Boolean) : undefined,
    };

    if (provider === 'openrouter') {
        url = 'https://openrouter.ai/api/v1/chat/completions';
        headers = { 
            'Authorization': `Bearer ${UserService.getApiKey()}`, // <-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'HTTP-Referer': 'https://sarega.github.io/PromptPrim/',
            'X-Title': 'PromptPrim' 
        };

        const safeParams = {
            temperature: commonParams.temperature,
            top_p: commonParams.top_p,
            max_tokens: commonParams.max_tokens,
        };

        // [FIX] ‡∏™‡πà‡∏á modelData ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô getCapability
        if (getCapability(modelData, 'top_k') && commonParams.top_k > 0) {
            safeParams.top_k = commonParams.top_k;
        }
        if (getCapability(modelData, 'penalties')) {
            safeParams.presence_penalty = commonParams.presence_penalty;
            safeParams.frequency_penalty = commonParams.frequency_penalty;
        }
        if (getCapability(modelData, 'seed') && commonParams.seed !== -1) {
            safeParams.seed = commonParams.seed;
        }
        if (commonParams.stop) {
            safeParams.stop = commonParams.stop;
        }

        body = { model: agent.model, messages, stream, ...safeParams };
        
        // [FIX] ‡∏™‡πà‡∏á modelData ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô getCapability
        if (getCapability(modelData, 'tools')) {
            body.tools = [{ "type": "Google Search" }];
        }

    } else { // ollama
        url = `${UserService.getOllamaUrl()}/api/chat`; // <-- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
        headers = { 'Content-Type': 'application/json' };
        
        const ollamaOptions = {
            temperature: commonParams.temperature,
            top_p: commonParams.top_p,
            top_k: commonParams.top_k,
            num_predict: commonParams.max_tokens,
            seed: commonParams.seed,
            stop: commonParams.stop,
        };
        Object.keys(ollamaOptions).forEach(key => (ollamaOptions[key] == null || Number.isNaN(ollamaOptions[key])) && delete ollamaOptions[key]);
        body = { model: agent.model, messages, stream, options: ollamaOptions };
    }

    return { url, headers, body, provider };
}


// =========================================================================
// == MAIN EXPORTED API FUNCTIONS (Unchanged, they use the new constructor)
// =========================================================================

export async function streamLLMResponse(agent, messages, onChunk) {
    const { url, headers, body, provider } = constructApiCall(agent, messages, true);
    try {
        stateManager.bus.publish('status:update', { message: `Responding with ${agent.model}...`, state: 'loading' });
        
        const startTime = performance.now();
        const response = await fetchWithTimeout(url, { method: 'POST', headers, body: JSON.stringify(body), signal: stateManager.getState().abortController?.signal });
        
        if (!response.ok) { throw new Error(`API Error: ${response.status} ${response.statusText}`); }
        
        const reader = response.body.getReader();
        const decoder = new TextDecoder("utf-8");
        let buffer = '';
        let fullResponseText = '';
        while (true) {
            const { value, done } = await reader.read();
            if (done) break;
            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop(); 
            for (const line of lines) {
                if (line.trim() === '' || line.startsWith(':')) continue;
                let token = '';
                try {
                    if (provider === 'openrouter') {
                        if (line.startsWith('data: ')) {
                            const jsonStr = line.replace(/^data: /, '').trim();
                            if (jsonStr === '[DONE]') break;
                            const data = JSON.parse(jsonStr);
                            token = data.choices?.[0]?.delta?.content || '';
                        }
                    } else { // ollama
                        const data = JSON.parse(line);
                        token = data.message?.content || '';
                    }
                } catch (e) { console.warn("Skipping malformed JSON chunk:", line); }
                if (token) {
                    fullResponseText += token;
                    onChunk(token);
                }
            }
        }
        
        const endTime = performance.now();
        const duration = (endTime - startTime) / 1000; // Duration in seconds

        let usage = { prompt_tokens: 0, completion_tokens: 0 };
        if (provider === 'openrouter' && response.headers.has('x-openrouter-usage')) {
            try {
                usage = JSON.parse(response.headers.get('x-openrouter-usage'));
            } catch(e) { console.error("Could not parse usage header:", e); }
        } else {
            // Fallback for Ollama or if header is missing
            usage.prompt_tokens = estimateTokens(JSON.stringify(messages));
            usage.completion_tokens = estimateTokens(fullResponseText);
        }
        
        return { content: fullResponseText, usage, duration };

    } catch (error) {
        if (error.name !== 'AbortError') {
             console.error("Streaming failed:", error);
             stateManager.bus.publish('status:update', { message: `Error: ${error.message}`, state: 'error' });
        }
        throw error;
    }
}

export async function callLLM(agent, messages) {
    const { url, headers, body, provider } = constructApiCall(agent, messages, false);
    try {
        console.log('[API CALL]', { url, headers, body });
        const response = await fetchWithTimeout(url, { method: 'POST', headers, body: JSON.stringify(body) });
        if (!response.ok) { 
            const errorText = await response.text(); 
            throw new Error(`API Error: ${response.status} ${errorText}`); 
        }
        
        const data = await response.json();
        const content = (provider === 'openrouter' && data.choices?.length > 0) 
            ? data.choices[0].message.content 
            : data.message?.content;

        if (content === undefined) {
            throw new Error("Invalid API response structure.");
        }

        // ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô object ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á content ‡πÅ‡∏•‡∏∞ usage
        return {
            content: content,
            usage: data.usage || { prompt_tokens: 0, completion_tokens: 0 }
        };

    } catch (error) {
        console.error("callLLM failed:", error);
        throw error;
    }
}